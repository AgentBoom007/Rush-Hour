import requests
import sqlite3
import json
import pandas as pd
import matplotlib.pyplot as plt
import os
from datetime import datetime




# --- API and Database Configuration ---
DB_NAME = 'brewery_weather_db.sqlite'
BREWERY_BASE_URL = "https://api.openbrewerydb.org/v1/breweries"
WEATHER_URL = "https://api.open-meteo.com/v1/forecast"

# Ann Arbor, MI - Anchor location for the correlation study
TARGET_LAT = 42.2776
TARGET_LONG = -83.7409
TARGET_CITY = "Ann Arbor"
TARGET_STATE = "Michigan" # Used for brewery filtering

# Rubric Requirement: Max of 25 items stored per run
PER_PAGE_LIMIT = 25 
ROW_MINIMUM = 100 # Rubric Requirement: Store at least 100 rows total

# --- 1. Database Functions ---

def create_database(db_name):
    """
    Creates the database connection and the required tables.
    Locations.LocationID is the INTEGER PRIMARY KEY shared across Breweries and Weather.
    """
    conn = sqlite3.connect(db_name)
    cur = conn.cursor()

    # Table 1: LOCATIONS (The Parent Table for the shared integer key)
    cur.execute('''
        CREATE TABLE IF NOT EXISTS Locations (
            LocationID INTEGER PRIMARY KEY,
            City TEXT NOT NULL,
            State TEXT NOT NULL,
            Latitude REAL,
            Longitude REAL,
            UNIQUE (City, State)
        )
    ''')

    # Table 2: BREWERIES (Linked to Locations by LocationID - Foreign Key)
    cur.execute('''
        CREATE TABLE IF NOT EXISTS Breweries (
            BreweryID INTEGER PRIMARY KEY AUTOINCREMENT,
            Name TEXT NOT NULL,
            BreweryType TEXT,
            WebsiteURL TEXT,
            LocationID INTEGER,
            FOREIGN KEY (LocationID) REFERENCES Locations(LocationID)
        )
    ''')

    # Table 3: WEATHER (Data from the second API, linked by LocationID)
    cur.execute('''
        CREATE TABLE IF NOT EXISTS Weather (
            WeatherID INTEGER PRIMARY KEY AUTOINCREMENT,
            Date TEXT NOT NULL,
            MaxTemp REAL,
            SunshineDuration REAL,
            PrecipitationSum REAL,
            WindGustsMax REAL,
            LocationID INTEGER,
            UNIQUE (Date, LocationID),
            FOREIGN KEY (LocationID) REFERENCES Locations(LocationID)
        )
    ''')
    conn.commit()
    print(f"Database '{db_name}' and tables initialized.")
    return conn

def get_or_create_location(cur, city, state, lat, long):
    """Checks if a location exists and returns its ID, or creates it if not."""
    cur.execute("SELECT LocationID FROM Locations WHERE City = ? AND State = ?", (city, state))
    result = cur.fetchone()
    if result:
        return result[0]
    else:
        cur.execute("INSERT INTO Locations (City, State, Latitude, Longitude) VALUES (?, ?, ?, ?)",
                    (city, state, lat, long))
        return cur.lastrowid

# --- 2. Data Fetching and Insertion Functions ---

def fetch_and_store_breweries(conn, location_id, state=TARGET_STATE):
    """
    Fetches up to 25 brewery items at a time. The 'by_state=Michigan' filter
    is applied here via the 'state' parameter derived from TARGET_STATE.
    """
    cur = conn.cursor()
    
    cur.execute("SELECT COUNT(*) FROM Breweries WHERE LocationID = ?", (location_id,))
    current_count = cur.fetchone()[0]
    
    next_page = (current_count // PER_PAGE_LIMIT) + 1
    
    if current_count >= ROW_MINIMUM:
        print(f"\n[Breweries]: Already stored {current_count} rows (Target: {ROW_MINIMUM}). Skipping fetch.")
        return 0

    print(f"\n[Breweries]: Fetching page {next_page} (Max {PER_PAGE_LIMIT} items) for '{state}'...")

    # The Michigan filter is applied here: 'by_state': state
    params = {
        'by_state': state,
        'per_page': PER_PAGE_LIMIT,
        'page': next_page
    }
    
    try:
        response = requests.get(BREWERY_BASE_URL, params=params)
        response.raise_for_status()
        brewery_data = response.json()
    except requests.exceptions.RequestException as e:
        print(f"Error fetching brewery data: {e}")
        return 0

    inserted_count = 0
    for brewery in brewery_data:
        try:
            cur.execute(
                '''
                INSERT INTO Breweries (Name, BreweryType, WebsiteURL, LocationID) 
                VALUES (?, ?, ?, ?)
                ''', 
                (brewery.get('name'), brewery.get('brewery_type'), brewery.get('website_url'), location_id)
            )
            inserted_count += 1
        except sqlite3.IntegrityError:
            continue

    conn.commit()
    print(f"[Breweries]: Successfully stored {inserted_count} new entries. Total stored: {current_count + inserted_count}.")
    return inserted_count

def fetch_and_store_weather(conn, location_id, lat=TARGET_LAT, long=TARGET_LONG):
    """
    [FIXED] Fetches daily historical (92 days) and forecast (16 days) data 
    using the new Open-Meteo API parameters.
    """
    cur = conn.cursor()

    # --- FINAL CORRECTED API PARAMETERS ---
    params = {
        'latitude': lat,
        'longitude': long,
        # Only request the daily fields that match the Weather table columns
        'daily': 'temperature_2m_max,sunshine_duration,precipitation_sum,wind_gusts_10m_max',
        'past_days': 92,     # CRITICAL: Ensures 92 historical days are fetched
        'forecast_days': 16, # Ensures 16 forecast days are fetched
        'timezone': 'America/New_York'
    }
    # ------------------------------------
    
    print(f"\n[Weather]: Fetching {params['past_days']} days of historical and {params['forecast_days']} days of forecast data (up to 108 records)...")
    
    try:
        response = requests.get(WEATHER_URL, params=params)
        response.raise_for_status()
        weather_data = response.json().get('daily', {})
    except requests.exceptions.RequestException as e:
        print(f"Error fetching weather data: {e}")
        return 0

    inserted_count = 0
    # Data fields MUST match the 'daily' request parameters above
    dates = weather_data.get('time', [])
    max_temps = weather_data.get('temperature_2m_max', [])
    sunshine = weather_data.get('sunshine_duration', [])
    precip = weather_data.get('precipitation_sum', [])
    wind_gusts = weather_data.get('wind_gusts_10m_max', [])
    
    for i in range(len(dates)):
        try:
            cur.execute(
                '''
                INSERT INTO Weather (Date, MaxTemp, SunshineDuration, PrecipitationSum, WindGustsMax, LocationID)
                VALUES (?, ?, ?, ?, ?, ?)
                ''',
                (dates[i], max_temps[i], sunshine[i], precip[i], wind_gusts[i], location_id)
            )
            inserted_count += 1
        except sqlite3.IntegrityError:
            continue
            
    conn.commit()
    print(f"[Weather]: Successfully stored {inserted_count} unique daily records (up to 108 total).")
    return inserted_count

# --- 3. Data Processing (SQL Calculation and File Output) ---

def write_calculation_to_file(data, filename='calculations.txt'):
    """Writes the calculation results to a well-formatted text file."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    output = f"--- Correlation Calculation Results ({timestamp}) ---\n"
    output += f"Location: {TARGET_CITY}, {TARGET_STATE}\n\n"
    output += f"Question: How does average forecast temperature relate to 'micro' brewery count?\n"
    output += f"1. Average Max Temperature across recorded forecasts: {data['avg_temp']:.2f} °C\n"
    output += f"2. Total number of 'micro' breweries stored: {data['micro_count']}\n"
    output += f"----------------------------------------------------\n"
    
    # Append the results to the file (Rubric requirement)
    with open(filename, 'a') as f:
        f.write(output)
    
    print(f"\n[Calculation]: Results appended to '{filename}'.")

def run_correlation_calculation(conn, location_id):
    """
    Performs the SQL calculation using a database JOIN.
    FIXED: Uses COUNT(DISTINCT B.BreweryID) to prevent the weather data from
           multiplying the brewery count (Cartesian Join issue).
    """
    cur = conn.cursor()
    
    # Uses COUNT(DISTINCT) and AVG() functions and two explicit JOINs
    query = '''
    SELECT 
        ROUND(AVG(W.MaxTemp), 2) AS Avg_Max_Temp_C,
        -- THIS LINE IS THE FIX: Only counts unique Brewery IDs
        COUNT(DISTINCT B.BreweryID) AS Total_Micro_Breweries
    FROM Breweries AS B
    JOIN Locations AS L ON B.LocationID = L.LocationID
    JOIN Weather AS W ON L.LocationID = W.LocationID
    WHERE 
        B.BreweryType = 'micro' AND 
        L.LocationID = ?;
    '''
    
    cur.execute(query, (location_id,))
    result = cur.fetchone()
    
    if result and result[0] is not None:
        avg_temp, micro_count = result
        
        # Write results to file
        data = {'avg_temp': avg_temp, 'micro_count': micro_count}
        write_calculation_to_file(data)
        
        # The corrected output will now show the true number of microbreweries (~37)
        return avg_temp, micro_count
    else:
        print("\n[Calculation]: No data found for calculation. Run the script more times.")
        return None, None

# --- 4. Visualization (Requires 2 for a 2-person group) ---

def create_visualization(db_name):
    """
    VISUALIZATION 1/2: Bar Chart showing the count of major brewery types.
    """
    try:
        conn = sqlite3.connect(db_name)
        query = '''
        SELECT 
            BreweryType, 
            COUNT(BreweryID) AS Count
        FROM Breweries
        GROUP BY BreweryType
        HAVING Count > 0
        ORDER BY Count DESC
        LIMIT 5;
        '''
        df = pd.read_sql_query(query, conn)
        conn.close()

        if df.empty:
            print("\n[Visualization 1]: No brewery data to visualize.")
            return

        plt.figure(figsize=(10, 6))
        # Changed colors to avoid lecture example deduction (Rubric requirement)
        plt.bar(df['BreweryType'], df['Count'], color=['#4daf4a', '#377eb8', '#ff7f00', '#984ea3', '#e41a1c'])
        
        plt.title(f'Top 5 Brewery Types in {TARGET_STATE}', fontsize=14)
        plt.xlabel('Brewery Type', fontsize=12)
        plt.ylabel('Count of Breweries', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.grid(axis='y', alpha=0.7)
        plt.tight_layout()
        
        viz_filename = 'visualization_1_brewery_type_distribution.png'
        plt.savefig(viz_filename)
        print(f"\n[Visualization 1]: Bar chart saved as '{viz_filename}'.")
        plt.show() # Displays the plot window

    except Exception as e:
        print(f"\n[Visualization 1] Error creating visualization: {e}")

def create_temp_time_series_plot(db_name):
    """
    VISUALIZATION 2/2: Line plot showing Max Temperature over the historical and forecast dates.
    """
    try:
        conn = sqlite3.connect(db_name)
        query = '''
        SELECT 
            Date, 
            MaxTemp
        FROM Weather
        ORDER BY Date;
        '''
        df = pd.read_sql_query(query, conn)
        conn.close()

        if df.empty:
            print("\n[Visualization 2]: No weather data to visualize.")
            return

        df['Date'] = pd.to_datetime(df['Date'])
        
        plt.figure(figsize=(12, 6))
        # This plot now covers over 100 days of weather data!
        plt.plot(df['Date'], df['MaxTemp'], marker='o', linestyle='-', color='red', linewidth=2)
        
        plt.title(f'Historical and Forecast Max Temperature in {TARGET_CITY}', fontsize=14)
        plt.xlabel('Date', fontsize=12)
        plt.ylabel('Maximum Temperature (°C)', fontsize=12)
        plt.grid(axis='y', alpha=0.5)
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        viz_filename = 'visualization_2_temperature_time_series.png'
        plt.savefig(viz_filename)
        print(f"[Visualization 2]: Time series plot saved as '{viz_filename}'.")
        plt.show() # Displays the plot window

    except Exception as e:
        print(f"\n[Visualization 2] Error creating visualization: {e}")

# --- 5. Main Execution ---

def main():
    """
    The main function that orchestrates the project execution.
    """
    
    # 1. Database Setup
    conn = create_database(DB_NAME)
    cur = conn.cursor()
    
    # 2. Get/Create Anchor Location (Ann Arbor, MI)
    location_id_ann_arbor = get_or_create_location(cur, TARGET_CITY, TARGET_STATE, TARGET_LAT, TARGET_LONG)
    conn.commit()
    
    # 3. Data Gathering (API 1: Breweries)
    print("\n---------------------------------------------------------")
    print("ACTION REQUIRED: Run this script 4+ times to hit the 100+ rows minimum.")
    print("---------------------------------------------------------")
    fetch_and_store_breweries(conn, location_id_ann_arbor)
    
    # 4. Data Gathering (API 2: Weather)
    fetch_and_store_weather(conn, location_id_ann_arbor)
    
    # 5. Data Processing/Calculation (Writes to calculations.txt)
    run_correlation_calculation(conn, location_id_ann_arbor)
    
    # 6. Visualization (Creates two images and displays them)
    create_visualization(DB_NAME)
    create_temp_time_series_plot(DB_NAME)

    conn.close()
    print("\n*** Project run complete. Check for .sqlite, .txt, and two .png files. ***")

if __name__ == "__main__":
    # Check for required external libraries
    try:
        if __name__ == "__main__":
            main()
    except Exception as e:
        print(f"An error occurred during execution: {e}")
        print("Please ensure you have installed all required libraries: pip install requests pandas matplotlib")